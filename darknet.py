{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV3 implementation and testing using PytorchÂ¶\n",
    "\n",
    "\n",
    "## step 1: Making the network's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import variable\n",
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(file_path):\n",
    "    #read the layers and store every block as a dictionary\n",
    "    block = {}\n",
    "    blocks = [] \n",
    "    with open(file=file_path, mode='r') as file:\n",
    "        lines = file.read().split('\\n')\n",
    "        lines = [x for x in lines if (len(x)>0)]\n",
    "        lines = (x for x in lines if x[0] != '#')\n",
    "        lines = [x.rstrip().lstrip() for x in lines]\n",
    "    \n",
    "    for line in lines:\n",
    "        if line[0] == \"[\":\n",
    "            if len(block) != 0:\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "            block[\"type\"] = line[1:-1].rstrip()\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            block[key.rstrip()] = value.lstrip()\n",
    "    blocks.append(block)\n",
    "        \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmptyLayer, self).__init__()\n",
    "\n",
    "class DetectionLayer(nn.Module):\n",
    "    def __init__(self, anchors):\n",
    "        super(DetectionLayer, self).__init__()\n",
    "        self.anchors = anchors\n",
    "\n",
    "\n",
    "def create_modules(blocks):\n",
    "    net_info = blocks[0] # get the network info as stored in the first block\n",
    "    module_list = nn.ModuleList()  #network modules\n",
    "    prev_filters = 3       #stores the filters of the previous layer only\n",
    "    output_filters = []    #stores the filters of each layer\n",
    "    \n",
    "    for index, block in enumerate(blocks[1:]): #making a sequential module for each block containing the layers\n",
    "        module = nn.Sequential()\n",
    "        if(block['type'] == 'convolutional'):\n",
    "            try:\n",
    "                batch_normalize = int(block[\"batch_normalize\"])\n",
    "                bias = False\n",
    "            except:\n",
    "                batch_normalize = 0\n",
    "                bias = True                \n",
    "\n",
    "            filters = int(block[\"filters\"])\n",
    "            kernel_size = int(block[\"size\"])\n",
    "            kernel_stride = int(block[\"stride\"])\n",
    "            kernel_padding = int(block[\"pad\"])\n",
    "            activation = block[\"activation\"]\n",
    "            \n",
    "            if kernel_padding:\n",
    "                pad = (kernel_size - 1) // 2\n",
    "            else:\n",
    "                pad = 0\n",
    "            \n",
    "            conv = nn.Conv2d(prev_filters, filters, kernel_size, kernel_stride, pad, bias= bias)\n",
    "            module.add_module(\"conv{0}\".format(index), conv)\n",
    "            \n",
    "            if batch_normalize:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                module.add_module(\"batch_norm{0}\".format(index), bn)\n",
    "                \n",
    "            if activation == \"leaky\":\n",
    "                act = nn.LeakyReLU(0.1, inplace=True)\n",
    "                module.add_module(\"leaky{0}\".format(index), act)\n",
    "                \n",
    "            \n",
    "        elif(block['type'] == 'shortcut'):\n",
    "            shortcut = EmptyLayer()\n",
    "            module.add_module(\"emptylayer{0}\".format(index), shortcut)\n",
    "            \n",
    "            \n",
    "        elif(block['type'] == 'route'):\n",
    "            block['layers'] = block['layers'].split(',')\n",
    "            start = int(block['layers'][0])\n",
    "            \n",
    "            try:\n",
    "                end = int(block[\"layers\"][1])\n",
    "            except:\n",
    "                end = 0\n",
    "\n",
    "            # refer to all layers with negative indices\n",
    "            if start > 0:\n",
    "                start -= index\n",
    "            if end > 0:\n",
    "                end -= index\n",
    "                \n",
    "            route = EmptyLayer()\n",
    "            module.add_module(\"route{0}\".format(index), route)\n",
    "            \n",
    "            #getting the total filters out of this routing layer\n",
    "            if end < 0:\n",
    "                filters = output_filters[index + start] + output_filters[index + end]\n",
    "            else:\n",
    "                filters = output_filters[index + start]\n",
    "                \n",
    "        \n",
    "        elif(block['type'] == 'upsample'):\n",
    "            stride = int(block[\"stride\"])\n",
    "            upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "            module.add_module(\"upsample{0}\".format(index), upsample)\n",
    "            \n",
    "            \n",
    "        elif(block['type'] == \"yolo\"):\n",
    "            mask = block[\"mask\"].split(',')\n",
    "            mask = (int(m) for m in mask)\n",
    "            anchors = block[\"anchors\"].split(\",\")\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]\n",
    "            anchors = [anchors[i] for i in mask]\n",
    "            \n",
    "            detection = DetectionLayer(anchors)\n",
    "            module.add_module(\"detectionlayer{0}\".format(index), detection)\n",
    "            \n",
    "            \n",
    "        module_list.append(module)\n",
    "        prev_filters = filters\n",
    "        output_filters.append(filters)\n",
    "        \n",
    "    return (net_info, module_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self, cfg_file):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.blocks = parse_cfg(cfg_file)\n",
    "        self.info, self.module_list = create_modules(self.blocks)\n",
    "        \n",
    "    def load_weights(self, file_name):\n",
    "        file = open(file_name, 'rb')\n",
    "        self.header = torch.from_numpy(np.fromfile(file, np.int32, 5))\n",
    "        self.seen = self.header[3]\n",
    "        weights = np.fromfile(file, np.int32)\n",
    "\n",
    "        ptr = 0\n",
    "        for i in range(len(self.module_list)):\n",
    "            module_type = self.blocks[i+1][\"type\"]\n",
    "            if module_type == \"convolutional\":\n",
    "                model = self.module_list[i]\n",
    "                conv = model[0]\n",
    "                if 'batch_normalization' in self.blocks[i+1]:\n",
    "                    bn = model[1]\n",
    "\n",
    "                    num_bn_biases = bn.bias.numel()   #store number of biases in this batch normalization\n",
    "\n",
    "                    #load the weights and biases of this batch normalization into variables\n",
    "                    bn_biases = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_weights = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_running_mean = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_running_var = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_biases = bn_biases.view(*bn.bias.shape)\n",
    "                    bn_weights = bn_weights.view(*bn.weight.shape)\n",
    "                    bn_running_mean = bn_running_mean.view(*bn.running_mean.shape)\n",
    "                    bn_running_var = bn_running_var.view(*bn.running_var.shape)\n",
    "\n",
    "                    bn,bias.data.copy_(bn_biases)\n",
    "                    bn.weights.data.copy_(bn_weights)\n",
    "                    bn.running_mean.data.copy_(bn_running_mean)\n",
    "                    bn.running_var.data.copy_(bn_running_var)\n",
    "\n",
    "                else:\n",
    "                    try:\n",
    "                        num_conv_biases = conv.bias.numel()\n",
    "                        conv_biases = torch.from_numpy(weights[ptr:ptr+num_conv_biases])\n",
    "                        ptr += num_conv_biases\n",
    "\n",
    "                        conv_biases = conv_biases.view(*conv.bias.shape)\n",
    "\n",
    "                        conv.bias.data.copy_(conv_biases)\n",
    "                    except:\n",
    "                        #print(\"conv_layer {0} has no biases\".format(i))\n",
    "                        continue\n",
    "\n",
    "                num_conv_weights = conv.weight.numel()\n",
    "                conv_weights = torch.from_numpy(weights[ptr:ptr+num_conv_weights])\n",
    "                ptr += num_conv_weights\n",
    "                \n",
    "                conv_weights = conv_weights.view(*conv.weight.shape)\n",
    "                conv.weight.data.copy_(conv_weights)\n",
    "    \n",
    "        \n",
    "    def forward(self, x, CUDA):\n",
    "        modules = self.blocks[1:]\n",
    "        outputs = {}   #stores the output of each layer to perform routing\n",
    "        write = 0\n",
    "        for i, module in enumerate(modules):\n",
    "            if (module[\"type\"] == \"convolutional\" or module[\"type\"] == \"upsample\"):\n",
    "                x = self.module_list[i](x)\n",
    "                \n",
    "                \n",
    "            elif (module[\"type\"] == \"route\"):\n",
    "                layers = module[\"layers\"]\n",
    "                layers = [int(l) for l in layers]\n",
    "                \n",
    "                if (layers[0] > 0):\n",
    "                    layers[0] -= i\n",
    "                    \n",
    "                if len(layers) == 1:\n",
    "                    x = outputs[i + (layers[0])]\n",
    "                    \n",
    "                else:\n",
    "                    if (layers[1]) > 0:\n",
    "                        layers [1] -= i\n",
    "                        \n",
    "                    map1 = outputs[i + layers[0]]\n",
    "                    map2 = outputs[i + layers[1]]\n",
    "                    x = torch.cat((map1, map2), 1 )   #concatenate the feature maps of the referenced layers\n",
    "                \n",
    "            elif(module[\"type\"] == \"shortcut\"):\n",
    "                layer = int(module[\"from\"])\n",
    "                x = outputs[i-1] + outputs[i + layer] #add the feature maps of the referenced layers\n",
    "                \n",
    "            elif(module[\"type\"] == \"yolo\"):\n",
    "                anchors = self.module_list[i][0].anchors\n",
    "                input_dim = int(self.info[\"height\"])\n",
    "                num_classes = int(module[\"classes\"])\n",
    "                \n",
    "                \n",
    "                x = x.data\n",
    "                \n",
    "                x = predict_transform(x, input_dim, anchors, num_classes, CUDA)\n",
    "                if not write:              \n",
    "                    detections = x\n",
    "                    write = 1\n",
    "\n",
    "                else:       \n",
    "                    detections = torch.cat((detections, x), 1)\n",
    "\n",
    "            outputs[i] = x\n",
    "        \n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = int(info['height'])\n",
    "width = int(info['width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input(height, width):\n",
    "    img = cv2.imread(\"dog-cycle-car.png\")\n",
    "    img = cv2.resize(img, (height,width))          #Resize to the model input dimensions\n",
    "    img_ =  img[:,:,::-1].transpose((2,0,1))  # convert BGR to RGB\n",
    "    img_ = img_[np.newaxis,:,:,:]/255.0       #Add a channel at 0 (for batch) and Normalise\n",
    "    img_ = torch.from_numpy(img_).float()     \n",
    "    img_ = Variable(img_)                     \n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"yolov3.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the pre-trained weights\n",
    "\n",
    "#wget https://pjreddie.com/media/files/yolov3.weights\n",
    "\n",
    "model.load_weights('yolov3.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = get_test_input(height, width)\n",
    "pred = model(inp, CUDA=False)\n",
    "print (pred)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python3 (cv-nd)",
   "language": "python",
   "name": "cv-nd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
