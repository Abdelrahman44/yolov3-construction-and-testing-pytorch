{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV3 implementation and testing using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: Making the network's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import variable\n",
    "import numpy as np\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(file_path):\n",
    "    #read the layers and store every block as a dictionary\n",
    "    block = {}\n",
    "    blocks = []\n",
    "    with open(file=file_path, mode='r') as file:\n",
    "        lines = file.read().split('\\n')\n",
    "        lines = [x for x in lines if (len(x)>0)]\n",
    "        lines = (x for x in lines if x[0] != '#')\n",
    "        lines = [x.rstrip().lstrip() for x in lines]\n",
    "    \n",
    "    for line in lines:\n",
    "        if line[0] == \"[\":\n",
    "            if len(block) != 0:\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "            block[\"type\"] = line[1:-1].rstrip()\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            block[key.rstrip()] = value.lstrip()\n",
    "    blocks.append(block)\n",
    "        \n",
    "    return blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'convolutional', 'batch_normalize': '1', 'filters': '32', 'size': '3', 'stride': '1', 'pad': '1', 'activation': 'leaky'}\n"
     ]
    }
   ],
   "source": [
    "yolo_blocks = parse_cfg('yolov3.cfg')\n",
    "print(yolo_blocks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmptyLayer, self).__init__()\n",
    "\n",
    "class DetectionLayer(nn.Module):\n",
    "    def __init__(self, anchors):\n",
    "        super(DetectionLayer, self).__init__()\n",
    "        self.anchors = anchors\n",
    "\n",
    "\n",
    "def create_modules(blocks):\n",
    "    net_info = blocks[0] # get the network info as stored in the first block\n",
    "    module_list = nn.ModuleList()\n",
    "    prev_filters = 3\n",
    "    #filters = 0\n",
    "    output_filters = []\n",
    "    \n",
    "    for index, block in enumerate(blocks[1:]): #making a sequential module for each block containing the layers\n",
    "        module = nn.Sequential()\n",
    "        if(block['type'] == 'convolutional'):\n",
    "            try:\n",
    "                batch_normalize = int(block[\"batch_normalize\"])\n",
    "                bias = False\n",
    "            except:\n",
    "                batch_normalize = 0\n",
    "                bias = True                \n",
    "\n",
    "            filters = int(block[\"filters\"])\n",
    "            kernel_size = int(block[\"size\"])\n",
    "            kernel_stride = int(block[\"stride\"])\n",
    "            kernel_padding = int(block[\"pad\"])\n",
    "            activation = block[\"activation\"]\n",
    "            \n",
    "            if kernel_padding:\n",
    "                pad = (kernel_size - 1) // 2\n",
    "            else:\n",
    "                pad = 0\n",
    "            \n",
    "            conv = nn.Conv2d(prev_filters, filters, kernel_size, kernel_stride, pad, bias= bias)\n",
    "            module.add_module(\"conv{0}\".format(index), conv)\n",
    "            \n",
    "            if batch_normalize:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                module.add_module(\"batch_norm{0}\".format(index), bn)\n",
    "                \n",
    "            if activation == \"leaky\":\n",
    "                act = nn.LeakyReLU(0.1, inplace=True)\n",
    "                module.add_module(\"leaky{0}\".format(index), act)\n",
    "                \n",
    "            \n",
    "        elif(block['type'] == 'shortcut'):\n",
    "            shortcut = EmptyLayer()\n",
    "            module.add_module(\"emptylayer{0}\".format(index), shortcut)\n",
    "            \n",
    "            \n",
    "        elif(block['type'] == 'route'):\n",
    "            print(block)\n",
    "            block['layers'] = block['layers'].split(',')\n",
    "            start = int(block['layers'][0])\n",
    "            \n",
    "            try:\n",
    "                end = int(block[\"layers\"][1])\n",
    "            except:\n",
    "                end = 0\n",
    "\n",
    "                \n",
    "            if start > 0:\n",
    "                start -= index\n",
    "            if end > 0:\n",
    "                end -= index\n",
    "                \n",
    "            route = EmptyLayer()\n",
    "            module.add_module(\"route{0}\".format(index), route)\n",
    "            \n",
    "            if end < 0:\n",
    "                filters = output_filters[index + start] + output_filters[index + end]\n",
    "            else:\n",
    "                filters = output_filters[index + start]\n",
    "                \n",
    "        \n",
    "        elif(block['type'] == 'upsample'):\n",
    "            stride = int(block[\"stride\"])\n",
    "            upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "            module.add_module(\"upsample{0}\".format(index), upsample)\n",
    "            \n",
    "            \n",
    "        elif(block['type'] == \"yolo\"):\n",
    "            mask = block[\"mask\"].split(',')\n",
    "            mask = (int(m) for m in mask)\n",
    "            anchors = block[\"anchors\"].split(\",\")\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]\n",
    "            anchors = [anchors[i] for i in mask]\n",
    "            \n",
    "            detection = DetectionLayer(anchors)\n",
    "            module.add_module(\"detectionlayer{0}\".format(index), detection)\n",
    "            \n",
    "            \n",
    "        module_list.append(module)\n",
    "        prev_filters = filters\n",
    "        output_filters.append(filters)\n",
    "        \n",
    "    return (net_info, module_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'route', 'layers': '-4'}\n",
      "{'type': 'route', 'layers': '-1, 61'}\n",
      "{'type': 'route', 'layers': '-4'}\n",
      "{'type': 'route', 'layers': '-1, 36'}\n"
     ]
    }
   ],
   "source": [
    "info, lis = create_modules(yolo_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (detectionlayer106): DetectionLayer()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis[106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self, cfg_file):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.blocks = parse_cfg(cfg_file)\n",
    "        self.info, self.module_list = create_modules(self.blocks)\n",
    "        \n",
    "    def forward(self, x, CUDA):\n",
    "        modules = self.blocks[1:]\n",
    "        outputs = {}\n",
    "        write = 0\n",
    "        for i, module in enumerate(modules):\n",
    "            if (module[\"type\"] == \"convolutional\" or module[\"type\"] == \"upsample\"):\n",
    "                x = self.module_list[i](x)\n",
    "                \n",
    "                \n",
    "            elif (module[\"type\"] == \"route\"):\n",
    "                layers = module[\"layers\"]\n",
    "                layers = [int(l) for l in layers]\n",
    "                \n",
    "                if (layers[0] > 0):\n",
    "                    layers[0] -= i\n",
    "                    \n",
    "                if len(layers) == 1:\n",
    "                    x = outputs[i + (layers[0])]\n",
    "                    \n",
    "                else:\n",
    "                    if (layers[1]) > 0:\n",
    "                        layers [1] -= i\n",
    "                        \n",
    "                    map1 = outputs[i + layers[0]]\n",
    "                    map2 = outputs[i + layers[1]]\n",
    "                    x = torch.cat((map1, map2), 1 )\n",
    "                \n",
    "            elif(module[\"type\"] == \"shortcut\"):\n",
    "                layer = int(module[\"from\"])\n",
    "                x = outputs[i-1] + outputs[i + layer]\n",
    "                \n",
    "            elif(module[\"type\"] == \"yolo\"):\n",
    "                anchors = self.module_list[i][0].anchors\n",
    "                input_dim = int(self.info[\"height\"])\n",
    "                num_classes = int(module[\"classes\"])\n",
    "                \n",
    "                \n",
    "                x = x.data\n",
    "                print(\" #in yolo, x dim : {0}\".format(x.shape))\n",
    "                \n",
    "                x = predict_transform(x, input_dim, anchors, num_classes, CUDA)\n",
    "                if not write:              #if no collector has been intialised. \n",
    "                    detections = x\n",
    "                    write = 1\n",
    "\n",
    "                else:       \n",
    "                    detections = torch.cat((detections, x), 1)\n",
    "\n",
    "            outputs[i] = x\n",
    "        \n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = int(info['height'])\n",
    "width = int(info['width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input(height, width):\n",
    "    img = cv2.imread(\"dog-cycle-car.png\")\n",
    "    img = cv2.resize(img, (height,width))          #Resize to the input dimension\n",
    "    img_ =  img[:,:,::-1].transpose((2,0,1))  # BGR -> RGB | H X W C -> C X H X W \n",
    "    img_ = img_[np.newaxis,:,:,:]/255.0       #Add a channel at 0 (for batch) | Normalise\n",
    "    img_ = torch.from_numpy(img_).float()     #Convert to float\n",
    "    img_ = Variable(img_)                     # Convert to Variable\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'route', 'layers': '-4'}\n",
      "{'type': 'route', 'layers': '-1, 61'}\n",
      "{'type': 'route', 'layers': '-4'}\n",
      "{'type': 'route', 'layers': '-1, 36'}\n",
      "image dimension : torch.Size([1, 3, 608, 608])\n",
      " #in yolo, x dim : torch.Size([1, 255, 19, 19])\n",
      " #in yolo, x dim : torch.Size([1, 255, 38, 38])\n",
      " #in yolo, x dim : torch.Size([1, 255, 76, 76])\n",
      "tensor([[[1.6454e+01, 1.6313e+01, 1.1573e+02,  ..., 3.9088e-01,\n",
      "          4.5618e-01, 5.3708e-01],\n",
      "         [1.3879e+01, 1.5626e+01, 1.5502e+02,  ..., 4.6558e-01,\n",
      "          4.6177e-01, 4.5955e-01],\n",
      "         [1.5942e+01, 1.6298e+01, 3.2926e+02,  ..., 5.1199e-01,\n",
      "          4.9673e-01, 5.3915e-01],\n",
      "         ...,\n",
      "         [6.0400e+02, 6.0383e+02, 9.2609e+00,  ..., 5.0169e-01,\n",
      "          5.4139e-01, 4.9346e-01],\n",
      "         [6.0410e+02, 6.0449e+02, 1.7437e+01,  ..., 5.1422e-01,\n",
      "          4.9967e-01, 5.8847e-01],\n",
      "         [6.0427e+02, 6.0411e+02, 3.5767e+01,  ..., 4.5829e-01,\n",
      "          5.4291e-01, 4.8189e-01]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ingramai/anaconda3/envs/cv-nd/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "model = Darknet(\"yolov3.cfg\")\n",
    "inp = get_test_input(height, width)\n",
    "pred = model(inp, CUDA=False)\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (cv-nd)",
   "language": "python",
   "name": "cv-nd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
