{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV3 implementation and testing using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: Making the network's layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import variable\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cfg(file_path):\n",
    "    #read the layers and store every block as a dictionary\n",
    "    block = {}\n",
    "    blocks = [] \n",
    "    with open(file=file_path, mode='r') as file:\n",
    "        lines = file.read().split('\\n')\n",
    "        lines = [x for x in lines if (len(x)>0)]\n",
    "        lines = (x for x in lines if x[0] != '#')\n",
    "        lines = [x.rstrip().lstrip() for x in lines]\n",
    "    \n",
    "    for line in lines:\n",
    "        if line[0] == \"[\":\n",
    "            if len(block) != 0:\n",
    "                blocks.append(block)\n",
    "                block = {}\n",
    "            block[\"type\"] = line[1:-1].rstrip()\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            block[key.rstrip()] = value.lstrip()\n",
    "    blocks.append(block)\n",
    "        \n",
    "    return blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmptyLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmptyLayer, self).__init__()\n",
    "\n",
    "class DetectionLayer(nn.Module):\n",
    "    def __init__(self, anchors):\n",
    "        super(DetectionLayer, self).__init__()\n",
    "        self.anchors = anchors\n",
    "\n",
    "\n",
    "def create_modules(blocks):\n",
    "    net_info = blocks[0] # get the network info as stored in the first block\n",
    "    module_list = nn.ModuleList()  #network modules\n",
    "    prev_filters = 3       #stores the filters of the previous layer only\n",
    "    output_filters = []    #stores the filters of each layer\n",
    "    \n",
    "    for index, block in enumerate(blocks[1:]): #making a sequential module for each block containing the layers\n",
    "        module = nn.Sequential()\n",
    "        if(block['type'] == 'convolutional'):\n",
    "            try:\n",
    "                batch_normalize = int(block[\"batch_normalize\"])\n",
    "                bias = False\n",
    "            except:\n",
    "                batch_normalize = 0\n",
    "                bias = True                \n",
    "\n",
    "            filters = int(block[\"filters\"])\n",
    "            kernel_size = int(block[\"size\"])\n",
    "            kernel_stride = int(block[\"stride\"])\n",
    "            kernel_padding = int(block[\"pad\"])\n",
    "            activation = block[\"activation\"]\n",
    "            \n",
    "            if kernel_padding:\n",
    "                pad = (kernel_size - 1) // 2\n",
    "            else:\n",
    "                pad = 0\n",
    "            \n",
    "            conv = nn.Conv2d(prev_filters, filters, kernel_size, kernel_stride, pad, bias= bias)\n",
    "            module.add_module(\"conv{0}\".format(index), conv)\n",
    "            \n",
    "            if batch_normalize:\n",
    "                bn = nn.BatchNorm2d(filters)\n",
    "                module.add_module(\"batch_norm{0}\".format(index), bn)\n",
    "                \n",
    "            if activation == \"leaky\":\n",
    "                act = nn.LeakyReLU(0.1, inplace=True)\n",
    "                module.add_module(\"leaky{0}\".format(index), act)\n",
    "                \n",
    "            \n",
    "        elif(block['type'] == 'shortcut'):\n",
    "            shortcut = EmptyLayer()\n",
    "            module.add_module(\"emptylayer{0}\".format(index), shortcut)\n",
    "            \n",
    "            \n",
    "        elif(block['type'] == 'route'):\n",
    "            block['layers'] = block['layers'].split(',')\n",
    "            start = int(block['layers'][0])\n",
    "            \n",
    "            try:\n",
    "                end = int(block[\"layers\"][1])\n",
    "            except:\n",
    "                end = 0\n",
    "\n",
    "            # refer to all layers with negative indices\n",
    "            if start > 0:\n",
    "                start -= index\n",
    "            if end > 0:\n",
    "                end -= index\n",
    "                \n",
    "            route = EmptyLayer()\n",
    "            module.add_module(\"route{0}\".format(index), route)\n",
    "            \n",
    "            #getting the total filters out of this routing layer\n",
    "            if end < 0:\n",
    "                filters = output_filters[index + start] + output_filters[index + end]\n",
    "            else:\n",
    "                filters = output_filters[index + start]\n",
    "                \n",
    "        \n",
    "        elif(block['type'] == 'upsample'):\n",
    "            stride = int(block[\"stride\"])\n",
    "            upsample = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "            module.add_module(\"upsample{0}\".format(index), upsample)\n",
    "            \n",
    "            \n",
    "        elif(block['type'] == \"yolo\"):\n",
    "            mask = block[\"mask\"].split(',')\n",
    "            mask = (int(m) for m in mask)\n",
    "            anchors = block[\"anchors\"].split(\",\")\n",
    "            anchors = [int(a) for a in anchors]\n",
    "            anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]\n",
    "            anchors = [anchors[i] for i in mask]\n",
    "            \n",
    "            detection = DetectionLayer(anchors)\n",
    "            module.add_module(\"detectionlayer{0}\".format(index), detection)\n",
    "            \n",
    "            \n",
    "        module_list.append(module)\n",
    "        prev_filters = filters\n",
    "        output_filters.append(filters)\n",
    "        \n",
    "    return (net_info, module_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self, cfg_file):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.blocks = parse_cfg(cfg_file)\n",
    "        self.info, self.module_list = create_modules(self.blocks)\n",
    "        \n",
    "    def load_weights(self, file_name):\n",
    "        file = open(file_name, 'rb')\n",
    "        self.header = torch.from_numpy(np.fromfile(file, np.int32, 5))\n",
    "        self.seen = self.header[3]\n",
    "        weights = np.fromfile(file, np.int32)\n",
    "\n",
    "        ptr = 0\n",
    "        for i in range(len(self.module_list)):\n",
    "            module_type = self.blocks[i+1][\"type\"]\n",
    "            if module_type == \"convolutional\":\n",
    "                model = self.module_list[i]\n",
    "                conv = model[0]\n",
    "                if 'batch_normalization' in self.blocks[i+1]:\n",
    "                    bn = model[1]\n",
    "\n",
    "                    num_bn_biases = bn.bias.numel()   #store number of biases in this batch normalization\n",
    "\n",
    "                    #load the weights and biases of this batch normalization into variables\n",
    "                    bn_biases = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_weights = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_running_mean = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_running_var = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_biases = bn_biases.view(*bn.bias.shape)\n",
    "                    bn_weights = bn_weights.view(*bn.weight.shape)\n",
    "                    bn_running_mean = bn_running_mean.view(*bn.running_mean.shape)\n",
    "                    bn_running_var = bn_running_var.view(*bn.running_var.shape)\n",
    "\n",
    "                    bn,bias.data.copy_(bn_biases)\n",
    "                    bn.weights.data.copy_(bn_weights)\n",
    "                    bn.running_mean.data.copy_(bn_running_mean)\n",
    "                    bn.running_var.data.copy_(bn_running_var)\n",
    "\n",
    "                else:\n",
    "                    try:\n",
    "                        num_conv_biases = conv.bias.numel()\n",
    "                        conv_biases = torch.from_numpy(weights[ptr:ptr+num_conv_biases])\n",
    "                        ptr += num_conv_biases\n",
    "\n",
    "                        conv_biases = conv_biases.view(*conv.bias.shape)\n",
    "\n",
    "                        conv.bias.data.copy_(conv_biases)\n",
    "                    except:\n",
    "                        #print(\"conv_layer {0} has no biases\".format(i))\n",
    "                        continue\n",
    "\n",
    "                num_conv_weights = conv.weight.numel()\n",
    "                conv_weights = torch.from_numpy(weights[ptr:ptr+num_conv_weights])\n",
    "                ptr += num_conv_weights\n",
    "                \n",
    "                conv_weights = conv_weights.view(*conv.weight.shape)\n",
    "                conv.weight.data.copy_(conv_weights)\n",
    "    \n",
    "        \n",
    "    def forward(self, x, CUDA):\n",
    "        modules = self.blocks[1:]\n",
    "        outputs = {}   #stores the output of each layer to perform routing\n",
    "        write = 0\n",
    "        for i, module in enumerate(modules):\n",
    "            if (module[\"type\"] == \"convolutional\" or module[\"type\"] == \"upsample\"):\n",
    "                x = self.module_list[i](x)\n",
    "                \n",
    "                \n",
    "            elif (module[\"type\"] == \"route\"):\n",
    "                layers = module[\"layers\"]\n",
    "                layers = [int(l) for l in layers]\n",
    "                \n",
    "                if (layers[0] > 0):\n",
    "                    layers[0] -= i\n",
    "                    \n",
    "                if len(layers) == 1:\n",
    "                    x = outputs[i + (layers[0])]\n",
    "                    \n",
    "                else:\n",
    "                    if (layers[1]) > 0:\n",
    "                        layers [1] -= i\n",
    "                        \n",
    "                    map1 = outputs[i + layers[0]]\n",
    "                    map2 = outputs[i + layers[1]]\n",
    "                    x = torch.cat((map1, map2), 1 )   #concatenate the feature maps of the referenced layers\n",
    "                \n",
    "            elif(module[\"type\"] == \"shortcut\"):\n",
    "                layer = int(module[\"from\"])\n",
    "                x = outputs[i-1] + outputs[i + layer] #add the feature maps of the referenced layers\n",
    "                \n",
    "            elif(module[\"type\"] == \"yolo\"):\n",
    "                anchors = self.module_list[i][0].anchors\n",
    "                input_dim = int(self.info[\"height\"])\n",
    "                num_classes = int(module[\"classes\"])\n",
    "                \n",
    "                \n",
    "                x = x.data\n",
    "                \n",
    "                x = predict_transform(x, input_dim, anchors, num_classes, CUDA)\n",
    "                if not write:              \n",
    "                    detections = x\n",
    "                    write = 1\n",
    "\n",
    "                else:       \n",
    "                    detections = torch.cat((detections, x), 1)\n",
    "\n",
    "            outputs[i] = x\n",
    "        \n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = int(info['height'])\n",
    "width = int(info['width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input(height, width):\n",
    "    img = cv2.imread(\"dog-cycle-car.png\")\n",
    "    img = cv2.resize(img, (height,width))          #Resize to the model input dimensions\n",
    "    img_ =  img[:,:,::-1].transpose((2,0,1))  # convert BGR to RGB\n",
    "    img_ = img_[np.newaxis,:,:,:]/255.0       #Add a channel at 0 (for batch) and Normalise\n",
    "    img_ = torch.from_numpy(img_).float()     \n",
    "    img_ = Variable(img_)                     \n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet(\"yolov3.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the pre-trained weights\n",
    "\n",
    "#wget https://pjreddie.com/media/files/yolov3.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('yolov3.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.2000e+01, 3.2000e+01, 0.0000e+00,  ..., 4.1560e-39,\n",
      "          4.1560e-39, 4.1560e-39],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.1560e-39,\n",
      "          4.1560e-39, 4.1560e-39],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.1560e-39,\n",
      "          4.1560e-39, 4.1560e-39],\n",
      "         ...,\n",
      "         [6.0000e+02, 6.0000e+02,        inf,  ..., 1.0000e+00,\n",
      "          4.1560e-39, 4.1560e-39],\n",
      "         [6.0000e+02, 6.0000e+02, 0.0000e+00,  ..., 4.1560e-39,\n",
      "          4.1560e-39, 4.1560e-39],\n",
      "         [6.0000e+02, 6.0000e+02, 0.0000e+00,  ..., 4.1560e-39,\n",
      "          4.1560e-39, 4.1560e-39]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ingramai/anaconda3/envs/cv-nd/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    }
   ],
   "source": [
    "inp = get_test_input(height, width)\n",
    "pred = model(inp, CUDA=False)\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   2,    6,   16,  ..., 7359, 7360, 7361])\n",
      "tensor([ 576, 1181, 1190, 1204, 1243, 1267, 1268, 1287, 1292, 1297, 1303, 1321,\n",
      "        1322, 1325, 1326, 1349, 1350, 1364, 1371, 1400, 1402, 1429, 1458, 1459,\n",
      "        1469, 1470, 1483, 1491, 1518, 1532, 1534, 1543, 1545, 1554, 1555, 1560,\n",
      "        1577, 1579, 1596, 1609, 1610, 1612, 1617, 1618, 1622, 1624, 1630, 1690,\n",
      "        1692, 1728, 1765, 1772, 1774, 1782, 1810, 1820, 1846, 1865, 1876, 1883,\n",
      "        1895, 1938, 1951, 1972, 2006, 2026, 2051, 2076, 2080, 2081, 2086, 2089,\n",
      "        2098, 2100, 2108, 2174, 2180, 2187, 2239, 2244, 2263, 2265, 2345, 2346,\n",
      "        2355, 2379, 2388, 2406, 2429, 2432, 2434, 2496, 2504, 2507, 2514, 2583,\n",
      "        2588, 2591, 2620, 2623, 2662, 2666, 2672, 2687, 2720, 2747, 2781, 2783,\n",
      "        2824, 2845, 2847, 2851, 2855, 2861, 2885, 2889, 2894, 2898, 2902, 2923,\n",
      "        2977, 2987, 2990, 3008, 3014, 3017, 3022, 3061, 3083, 3088, 3093, 3094,\n",
      "        3107, 3127, 3162, 3232, 3233, 3234, 3235, 3282, 3300, 3314, 3316, 3349,\n",
      "        3400, 3405, 3414, 3416, 3433, 3442, 3446, 3456, 3463, 3478, 3479, 3480,\n",
      "        3494, 3505, 3553, 3558, 3572, 3701, 3711, 3712, 3823, 3829, 3873, 3888,\n",
      "        3978, 4008, 4098, 4156, 4164, 4174, 4179, 4195, 4243, 4257, 4279, 4352,\n",
      "        4362, 4425, 4443, 4451, 4466, 4469, 4477, 4506, 4507, 4582, 4627, 4634,\n",
      "        4638, 4677, 4697, 4711, 4768, 4827, 4863, 4865, 4869, 4884, 4895, 4918,\n",
      "        4956, 4995, 5006, 5047, 5051, 5128, 5196, 5208, 5267, 5293, 5328, 5389,\n",
      "        5420, 5482, 5484, 5486, 5488, 5616, 5665, 5680, 5769, 5793, 5811, 5850,\n",
      "        5867, 5871, 5968, 6000, 6070, 6079, 6110, 6111, 6183, 6223, 6273, 6275,\n",
      "        6292, 6309, 6354, 6409, 6447, 6448, 6470, 6486, 6527, 6528, 6566, 6642,\n",
      "        6649, 6650, 6660, 6710, 6725, 6730, 6734, 6776, 6796, 6800, 6805, 6806,\n",
      "        6808, 6813, 6868, 6874, 6877, 6878, 6879, 6880, 6882, 6932, 6955, 6957,\n",
      "        6959, 6960, 6968, 6991, 7034, 7036, 7042, 7044, 7048, 7098, 7118, 7133,\n",
      "        7134, 7136, 7186, 7322])\n",
      "torch.Size([292, 8]) torch.Size([2415, 8])\n",
      "tensor([  58,   60,   62,   82,   87,   88,   91,   96,   97,   98,   99,  102,\n",
      "         105,  107,  123,  126,  127,  128,  143,  145,  155,  157,  158,  159,\n",
      "         163,  165,  169,  170,  176,  179,  189,  196,  206,  216,  221,  222,\n",
      "         223,  225,  226,  247,  249,  250,  269,  286,  293,  294,  315,  317,\n",
      "         318,  329,  337,  338,  344,  349,  357,  374,  377,  379,  382,  383,\n",
      "         384,  390,  393,  394,  396,  400,  408,  410,  413,  414,  421,  427,\n",
      "         431,  436,  445,  459,  460,  461,  466,  469,  472,  487,  488,  489,\n",
      "         493,  510,  512,  534,  538,  540,  548,  560,  567,  568,  569,  586,\n",
      "         594,  615,  633,  650,  679,  680,  704,  708,  710,  712,  713,  736,\n",
      "         742,  766,  768,  782,  783,  795,  805,  820,  851, 1057, 1059, 1061,\n",
      "        1068, 1071, 1073, 1086, 1101, 1107, 1113, 1114, 1125, 1126, 1129, 1130,\n",
      "        1137, 1138, 1140, 1151, 1152, 1158, 1160, 1164, 1166, 1168, 1173, 1175,\n",
      "        1178, 1180, 1182, 1183, 1184, 1187, 1191, 1196, 1201, 1218, 1221, 1224,\n",
      "        1234, 1239, 1245, 1261, 1277, 1294, 1320, 1333, 1339, 1345, 1346, 1348,\n",
      "        1359, 1363, 1368, 1377, 1381, 1388, 1391, 1396, 1404, 1414, 1422, 1430,\n",
      "        1436, 1440, 1442, 1451, 1452, 1454, 1471, 1472, 1484, 1493, 1505, 1515,\n",
      "        1517, 1524, 1526, 1551, 1556, 1557, 1568, 1574, 1578, 1606, 1607, 1614,\n",
      "        1619, 1627, 1640, 1643, 1665, 1666, 1680, 1689, 1691, 1702, 1704, 1706,\n",
      "        1719, 1727, 1730, 1731, 1733, 1737, 1740, 1752, 1755, 1761, 1763, 1768,\n",
      "        1769, 1775, 1776, 1777, 1786, 1797, 1798, 1803, 1805, 1806, 1816, 1830,\n",
      "        1834, 1842, 1848, 1856, 1857, 1866, 1885, 1889, 1899, 1916, 1919, 1925,\n",
      "        1931, 1932, 1939, 1941, 1942, 1945, 1946, 1952, 1953, 1967, 1971, 1973,\n",
      "        1978, 2003, 2013, 2018, 2022, 2028, 2029, 2030, 2046, 2052, 2056, 2066,\n",
      "        2069, 2073, 2084, 2085, 2090, 2097, 2102, 2107, 2113, 2127, 2129, 2141,\n",
      "        2162, 2165, 2169, 2173, 2175, 2178, 2179, 2183, 2193, 2211, 2219, 2223,\n",
      "        2227, 2248, 2252, 2257, 2259, 2266, 2274, 2277, 2282, 2287, 2293, 2295,\n",
      "        2297, 2323, 2326, 2332, 2333, 2335, 2339, 2341, 2342, 2344, 2347, 2351,\n",
      "        2353, 2354, 2357, 2359, 2376, 2385, 2403, 2405, 2408, 2417, 2423, 2427,\n",
      "        2430, 2433, 2436, 2437, 2459, 2472, 2482, 2483, 2486, 2492, 2493, 2497,\n",
      "        2501, 2502, 2505, 2508, 2509, 2510, 2521, 2542, 2543, 2548, 2575, 2578,\n",
      "        2592, 2593, 2595, 2606, 2619, 2622, 2639, 2648, 2659, 2661, 2668, 2673,\n",
      "        2674, 2676, 2684, 2702, 2704, 2717, 2726, 2740, 2745, 2755, 2757, 2759,\n",
      "        2760, 2762, 2802, 2805, 2821, 2822, 2827, 2830, 2832, 2839, 2846, 2854,\n",
      "        2864, 2865, 2866, 2877, 2897, 2900, 2906, 2907, 2910, 2912, 2914, 2922,\n",
      "        2933, 2945, 2960, 2971, 2975, 2981, 2984, 2988, 2996, 3001, 3007, 3009,\n",
      "        3011, 3018, 3024, 3026, 3031, 3043, 3044, 3047, 3050, 3055, 3058, 3060,\n",
      "        3072, 3079, 3090, 3092, 3098, 3101, 3103, 3122, 3131, 3135, 3136, 3158,\n",
      "        3166, 3168, 3171, 3177, 3178, 3180, 3183, 3197, 3205, 3208, 3209, 3219,\n",
      "        3226, 3239, 3252, 3274, 3280, 3294, 3295, 3318, 3323, 3345, 3346, 3350,\n",
      "        3369, 3378, 3380, 3381, 3396, 3407, 3422, 3428, 3430, 3457, 3458, 3477,\n",
      "        3483, 3485, 3487, 3500, 3503, 3512, 3515, 3528, 3532, 3533, 3543, 3552,\n",
      "        3556, 3557, 3559, 3561, 3564, 3567, 3574, 3577, 3598, 3609, 3616, 3617,\n",
      "        3624, 3626, 3636, 3639, 3642, 3644, 3645, 3648, 3654, 3664, 3702, 3707,\n",
      "        3715, 3729, 3731, 3734, 3736, 3741, 3748, 3750, 3754, 3757, 3758, 3769,\n",
      "        3773, 3775, 3780, 3792, 3813, 3822, 3833, 3843, 3850, 3851, 3878, 3890,\n",
      "        3893, 3900, 3906, 3912, 3926, 3939, 3952, 3956, 3970, 3983, 4007, 4018,\n",
      "        4032, 4036, 4041, 4042, 4056, 4059, 4066, 4069, 4071, 4095, 4097, 4099,\n",
      "        4101, 4110, 4145, 4159, 4166, 4167, 4168, 4171, 4183, 4185, 4188, 4198,\n",
      "        4202, 4208, 4224, 4233, 4250, 4258, 4261, 4266, 4268, 4276, 4278, 4280,\n",
      "        4281, 4283, 4284, 4290, 4294, 4306, 4316, 4319, 4328, 4332, 4334, 4351,\n",
      "        4365, 4376, 4383, 4385, 4403, 4408, 4413, 4416, 4418, 4420, 4421, 4428,\n",
      "        4434, 4437, 4452, 4468, 4470, 4475, 4485, 4497, 4503, 4509, 4516, 4517,\n",
      "        4531, 4537, 4542, 4567, 4587, 4595, 4601, 4602, 4607, 4623, 4625, 4630,\n",
      "        4637, 4642, 4662, 4671, 4682, 4683, 4685, 4691, 4692, 4693, 4696, 4730,\n",
      "        4737, 4739, 4766, 4773, 4787, 4794, 4795, 4797, 4800, 4818, 4828, 4839,\n",
      "        4841, 4846, 4848, 4864, 4866, 4872, 4885, 4894, 4908, 4916, 4923, 4924,\n",
      "        4926, 4928, 4933, 4939, 4948, 4953, 4964, 4968, 4982, 4990, 5019, 5022,\n",
      "        5029, 5031, 5042, 5046, 5082, 5083, 5098, 5103, 5121, 5124, 5127, 5132,\n",
      "        5144, 5155, 5157, 5200, 5207, 5210, 5211, 5216, 5248, 5251, 5263, 5296,\n",
      "        5298, 5318, 5320, 5321, 5322, 5326, 5329, 5332, 5335, 5351, 5354, 5367,\n",
      "        5391, 5392, 5396, 5399, 5426, 5427, 5439, 5461, 5483, 5490, 5492, 5498,\n",
      "        5507, 5529, 5531, 5545, 5549, 5572, 5578, 5580, 5605, 5611, 5636, 5643,\n",
      "        5655, 5660, 5670, 5685, 5687, 5689, 5695, 5741, 5771, 5779, 5781, 5790,\n",
      "        5812, 5821, 5825, 5843, 5887, 5897, 5924, 5956, 5962, 5981, 6094, 6108,\n",
      "        6188, 6192, 6194, 6272, 6345, 6377, 6395, 6427, 6442, 6476, 6511, 6529,\n",
      "        6540, 6549, 6560, 6596, 6614, 6618, 6684, 6703, 6704, 6706, 6720, 6773,\n",
      "        6785, 6787, 6859, 6909, 6911, 6916, 6947, 6978, 7003, 7016, 7056, 7103,\n",
      "        7109, 7144, 7165, 7173, 7176, 7197, 7202, 7204, 7240, 7246, 7259, 7263,\n",
      "        7265, 7281, 7291, 7292, 7294, 7296, 7306, 7311, 7320, 7334, 7336, 7338,\n",
      "        7351, 7358])\n",
      "torch.Size([830, 8]) torch.Size([2707, 8])\n",
      "tensor([   0,    3,    4,  ..., 7342, 7352, 7353])\n",
      "torch.Size([1125, 8]) torch.Size([3537, 8])\n",
      "tensor([  41,   55,   56,  ..., 7235, 7248, 7270])\n",
      "torch.Size([1001, 8]) torch.Size([4662, 8])\n",
      "tensor([ 806,  943, 1197, 1203, 1231, 1238, 1304, 1324, 1338, 1480, 1633, 1635,\n",
      "        1668, 1707, 1784, 2048, 2358, 2856, 3064, 3170, 3174, 3481, 3536, 3884,\n",
      "        3886, 3898, 4178, 4770, 4771, 6120, 6121])\n",
      "torch.Size([31, 8]) torch.Size([5663, 8])\n",
      "tensor([   7,   12,   47,   85,  113,  122,  134,  151,  161,  164,  178,  187,\n",
      "         198,  209,  212,  213,  227,  252,  265,  282,  287,  312,  324,  359,\n",
      "         373,  402,  417,  434,  458,  468,  482,  500,  509,  516,  520,  523,\n",
      "         529,  544,  546,  549,  552,  555,  606,  617,  640,  648,  670,  674,\n",
      "         676,  684,  709,  721,  729,  753,  775,  776,  780,  800,  810,  811,\n",
      "         813,  821,  833,  837,  839,  855,  862,  864,  905,  906,  907,  908,\n",
      "         912,  924,  934,  937,  938,  941,  942,  946,  948,  949,  950,  961,\n",
      "         965,  985,  986,  990,  999, 1013, 1023, 1024, 1034, 1035, 1036, 1049,\n",
      "        1076, 1077, 1084, 1135, 1198, 1200, 1251, 1271, 1275, 1285, 1331, 1584,\n",
      "        1647, 1677, 1960, 1968, 2041, 2116, 2138, 2225, 2271, 2311, 2499, 2533,\n",
      "        2772, 3015, 3291, 3374, 3427, 3584, 3713, 3795, 3818, 3856, 3882, 4016,\n",
      "        4165, 4173, 4175, 4251, 4308, 4441, 4449, 4557, 4626, 4684, 4755, 4810,\n",
      "        4873, 5004, 5198, 5422, 5512, 5641, 5647, 5720, 5817, 6245, 6495, 6506,\n",
      "        6777, 6783, 7027, 7208, 7210])\n",
      "torch.Size([161, 8]) torch.Size([5694, 8])\n",
      "tensor([  46,   53,   74,   77,   83,  101,  104,  112,  117,  140,  184,  203,\n",
      "         208,  218,  245,  296,  298,  314,  330,  419,  433,  467,  496,  557,\n",
      "         571,  584,  632,  666,  724,  725,  734,  781,  856,  881,  902,  926,\n",
      "         927,  973,  980,  982,  996, 1116, 1133, 1237, 1316, 1357, 1393, 1411,\n",
      "        1433, 1450, 1462, 1478, 1549, 1553, 1561, 1611, 1621, 1646, 1662, 1791,\n",
      "        1822, 1906, 1914, 1915, 1924, 1937, 1969, 2025, 2082, 2087, 2146, 2151,\n",
      "        2208, 2269, 2349, 2449, 2513, 2582, 2654, 2743, 2815, 2829, 3013, 3019,\n",
      "        3125, 3159, 3172, 3245, 3248, 3315, 3320, 3383, 3386, 3387, 3465, 3466,\n",
      "        3502, 3618, 3720, 3732, 3789, 3791, 3904, 3907, 3999, 4077, 4079, 4147,\n",
      "        4177, 4180, 4200, 4203, 4265, 4271, 4274, 4291, 4320, 4357, 4388, 4597,\n",
      "        4673, 4694, 4706, 4762, 4853, 4861, 4876, 4950, 5032, 5035, 5054, 5130,\n",
      "        5142, 5158, 5175, 5292, 5401, 5458, 5526, 5547, 5624, 5684, 5868, 5892,\n",
      "        5979, 6069])\n",
      "torch.Size([146, 8]) torch.Size([5855, 8])\n",
      "tensor([ 147,  174,  331, 1120, 1122, 1143, 1145, 1202, 1258, 1280, 1286, 1340,\n",
      "        1460, 1488, 1599, 1659, 1694, 1722, 1725, 1771, 1789, 1841, 1862, 1887,\n",
      "        1891, 1894, 1897, 1936, 1980, 1988, 1993, 2000, 2049, 2062, 2099, 2176,\n",
      "        2213, 2247, 2273, 2279, 2283, 2299, 2322, 2383, 2443, 2475, 2541, 2558,\n",
      "        2573, 2576, 2585, 2594, 2602, 2646, 2686, 2709, 2837, 2871, 2927, 2941,\n",
      "        2947, 2972, 3020, 3042, 3142, 3176, 3255, 3303, 3322, 3357, 3375, 3376,\n",
      "        3401, 3474, 3580, 3730, 3738, 3770, 3797, 3804, 3868, 3876, 3933, 3953,\n",
      "        3977, 4000, 4052, 4073, 4104, 4137, 4150, 4193, 4247, 4254, 4282, 4321,\n",
      "        4348, 4367, 4370, 4462, 4526, 4536, 4599, 4767, 4806, 4940, 4945, 4978,\n",
      "        4985, 5076, 5112, 5239, 5276, 5334, 5364, 5436, 5457, 5487, 5523, 5555,\n",
      "        5623, 5653, 5654, 5691, 5726, 5890, 6102, 6279, 6366, 6454, 6610, 6751,\n",
      "        6753, 6994, 7161, 7200, 7218, 7222])\n",
      "torch.Size([138, 8]) torch.Size([6001, 8])\n",
      "tensor([  49,   59,   61,   68,   76,   84,   89,   93,   94,  106,  111,  114,\n",
      "         133,  171,  177,  186,  192,  193,  195,  201,  210,  215,  231,  242,\n",
      "         257,  270,  272,  274,  283,  290,  308,  313,  328,  332,  336,  343,\n",
      "         351,  365,  380,  381,  392,  407,  439,  444,  449,  451,  455,  456,\n",
      "         475,  486,  521,  530,  539,  541,  542,  550,  558,  566,  570,  578,\n",
      "         592,  619,  627,  639,  641,  660,  667,  673,  675,  683,  689,  690,\n",
      "         691,  693,  697,  700,  705,  717,  719,  723,  727,  730,  748,  749,\n",
      "         750,  758,  759,  774,  778,  779,  784,  792,  807,  822,  834,  844,\n",
      "         859,  865,  868,  872,  892,  894,  922,  925,  929,  947,  952,  959,\n",
      "         974,  979,  993, 1015, 1020, 1027, 1039, 1041, 1052, 1058, 1060, 1063,\n",
      "        1170, 1278, 1335, 1392, 1550, 1558, 1597, 1655, 1714, 1838, 1958, 2040,\n",
      "        2126, 2163, 2233, 2264, 2461, 2551, 2670, 2750, 2860, 3048, 3049, 3120,\n",
      "        3258, 3343, 3398, 3426, 3718, 3746, 3828, 3862, 4075, 4363, 4439, 4615,\n",
      "        4805, 5033, 5078, 5203, 5229, 5254, 6007, 6019, 6072, 6076, 6207, 6347,\n",
      "        6368, 6411, 6420, 6575, 6829, 6979, 7172, 7205, 7207, 7257, 7299])\n",
      "torch.Size([179, 8]) torch.Size([6139, 8])\n",
      "tensor([  31,   92,  116,  267,  371,  397,  453,  502,  513,  764,  871,  879,\n",
      "        1067, 1109, 1110, 1128, 1142, 1153, 1157, 1163, 1188, 1189, 1192, 1208,\n",
      "        1209, 1220, 1228, 1232, 1236, 1249, 1252, 1255, 1262, 1270, 1273, 1274,\n",
      "        1283, 1284, 1289, 1290, 1296, 1305, 1306, 1311, 1315, 1317, 1334, 1343,\n",
      "        1347, 1352, 1353, 1355, 1358, 1360, 1362, 1378, 1379, 1383, 1385, 1386,\n",
      "        1389, 1394, 1397, 1406, 1407, 1408, 1412, 1413, 1415, 1439, 1443, 1453,\n",
      "        1456, 1477, 1479, 1494, 1495, 1497, 1520, 1536, 1538, 1540, 1546, 1552,\n",
      "        1562, 1566, 1567, 1571, 1575, 1585, 1588, 1590, 1595, 1604, 1628, 1636,\n",
      "        1642, 1644, 1649, 1657, 1671, 1675, 1682, 1683, 1723, 1732, 1734, 1738,\n",
      "        1739, 1741, 1742, 1754, 1759, 1764, 1770, 1788, 1790, 1800, 1807, 1814,\n",
      "        1823, 1824, 1832, 1843, 1847, 1852, 1855, 1858, 1864, 1869, 1870, 1877,\n",
      "        1882, 1886, 1888, 1890, 1896, 1905, 1907, 1913, 1917, 1920, 1921, 1926,\n",
      "        1929, 1930, 1940, 1943, 1970, 1976, 2008, 2012, 2014, 2019, 2023, 2043,\n",
      "        2054, 2060, 2063, 2083, 2088, 2096, 2128, 2130, 2131, 2134, 2139, 2145,\n",
      "        2155, 2157, 2159, 2164, 2167, 2182, 2192, 2194, 2196, 2205, 2209, 2214,\n",
      "        2216, 2226, 2228, 2231, 2232, 2234, 2237, 2242, 2249, 2251, 2256, 2258,\n",
      "        2260, 2270, 2276, 2298, 2318, 2324, 2331, 2336, 2340, 2348, 2352, 2370,\n",
      "        2373, 2390, 2393, 2396, 2412, 2414, 2418, 2419, 2431, 2435, 2438, 2439,\n",
      "        2454, 2457, 2460, 2464, 2484, 2488, 2517, 2523, 2525, 2539, 2540, 2549,\n",
      "        2566, 2568, 2596, 2599, 2617, 2625, 2627, 2638, 2645, 2653, 2657, 2665,\n",
      "        2675, 2678, 2699, 2703, 2708, 2710, 2712, 2728, 2735, 2751, 2767, 2771,\n",
      "        2775, 2779, 2801, 2806, 2812, 2817, 2826, 2828, 2834, 2835, 2838, 2840,\n",
      "        2842, 2843, 2867, 2869, 2876, 2881, 2893, 2899, 2905, 2909, 2916, 2934,\n",
      "        2935, 2944, 2946, 2965, 2969, 2974, 2985, 2993, 3002, 3004, 3016, 3025,\n",
      "        3030, 3038, 3040, 3053, 3059, 3082, 3089, 3091, 3099, 3100, 3106, 3108,\n",
      "        3113, 3115, 3116, 3119, 3121, 3128, 3129, 3133, 3137, 3138, 3141, 3153,\n",
      "        3154, 3160, 3163, 3165, 3175, 3189, 3201, 3203, 3223, 3228, 3230, 3236,\n",
      "        3237, 3238, 3251, 3253, 3254, 3262, 3273, 3281, 3288, 3301, 3310, 3313,\n",
      "        3321, 3327, 3354, 3356, 3358, 3361, 3362, 3364, 3365, 3372, 3384, 3385,\n",
      "        3389, 3391, 3397, 3408, 3412, 3419, 3435, 3437, 3444, 3451, 3459, 3460,\n",
      "        3482, 3507, 3537, 3548, 3560, 3566, 3578, 3583, 3592, 3594, 3611, 3615,\n",
      "        3619, 3630, 3634, 3649, 3651, 3663, 3669, 3670, 3677, 3684, 3703, 3704,\n",
      "        3723, 3733, 3735, 3737, 3739, 3767, 3774, 3790, 3800, 3802, 3806, 3824,\n",
      "        3825, 3857, 3864, 3875, 3881, 3887, 3889, 3899, 3901, 3903, 3911, 3913,\n",
      "        3920, 3921, 3923, 3927, 3941, 3951, 3972, 3981, 3990, 4005, 4009, 4012,\n",
      "        4031, 4034, 4037, 4064, 4067, 4070, 4076, 4080, 4084, 4102, 4112, 4142,\n",
      "        4143, 4149, 4153, 4163, 4169, 4172, 4176, 4182, 4184, 4187, 4189, 4192,\n",
      "        4216, 4228, 4267, 4270, 4272, 4275, 4289, 4329, 4333, 4335, 4345, 4358,\n",
      "        4359, 4371, 4375, 4404, 4414, 4415, 4419, 4438, 4440, 4442, 4446, 4448,\n",
      "        4454, 4456, 4464, 4476, 4505, 4522, 4530, 4533, 4538, 4540, 4541, 4543,\n",
      "        4544, 4552, 4594, 4606, 4612, 4613, 4618, 4628, 4647, 4675, 4688, 4698,\n",
      "        4701, 4703, 4707, 4724, 4735, 4751, 4757, 4763, 4802, 4804, 4819, 4833,\n",
      "        4836, 4843, 4845, 4847, 4849, 4862, 4870, 4880, 4898, 4899, 4901, 4914,\n",
      "        4917, 4922, 4934, 4942, 4946, 4957, 4963, 4965, 5001, 5016, 5020, 5023,\n",
      "        5026, 5030, 5050, 5063, 5095, 5107, 5123, 5137, 5141, 5143, 5153, 5162,\n",
      "        5171, 5180, 5188, 5201, 5205, 5213, 5217, 5231, 5245, 5264, 5284, 5338,\n",
      "        5352, 5368, 5383, 5384, 5387, 5393, 5395, 5398, 5402, 5440, 5449, 5463,\n",
      "        5467, 5475, 5478, 5493, 5495, 5505, 5515, 5517, 5518, 5527, 5534, 5542,\n",
      "        5548, 5550, 5551, 5552, 5556, 5560, 5576, 5579, 5581, 5585, 5588, 5590,\n",
      "        5631, 5650, 5657, 5682, 5683, 5686, 5692, 5717, 5727, 5742, 5756, 5777,\n",
      "        5796, 5827, 5829, 5848, 5863, 5876, 5882, 5885, 5888, 5895, 5904, 5918,\n",
      "        5978, 5997, 6021, 6027, 6044, 6055, 6057, 6060, 6066, 6091, 6096, 6099,\n",
      "        6101, 6106, 6118, 6171, 6182, 6186, 6187, 6195, 6198, 6222, 6252, 6276,\n",
      "        6297, 6298, 6300, 6305, 6306, 6313, 6325, 6331, 6333, 6387, 6405, 6415,\n",
      "        6418, 6431, 6438, 6449, 6451, 6463, 6474, 6482, 6496, 6503, 6505, 6532,\n",
      "        6534, 6546, 6551, 6573, 6599, 6637, 6676, 6681, 6683, 6707, 6729, 6731,\n",
      "        6733, 6757, 6759, 6778, 6786, 6797, 6816, 6822, 6856, 6876, 6883, 6886,\n",
      "        6898, 6914, 6920, 6931, 6937, 6938, 6939, 6943, 6950, 6953, 6954, 6969,\n",
      "        6972, 7004, 7017, 7022, 7039, 7041, 7064, 7065, 7066, 7069, 7087, 7089,\n",
      "        7107, 7119, 7158, 7198, 7199, 7201, 7209, 7278, 7285, 7286, 7289, 7300,\n",
      "        7308, 7316, 7321, 7331])\n",
      "torch.Size([724, 8]) torch.Size([6318, 8])\n",
      "tensor([  24,   43,   78,   95,  153,  246,  429,  497,  692,  836,  877,  978,\n",
      "         984, 1001, 1010, 1012, 1042, 1062, 1804, 1964, 2172, 2683, 3149, 3613,\n",
      "        5053, 5963, 7040, 7180, 7217])\n",
      "torch.Size([29, 8]) torch.Size([7042, 8])\n",
      "tensor([  69,   80,  130,  136,  299,  301,  307,  316,  320,  370,  372,  378,\n",
      "         409,  420,  441,  442,  443,  452,  471,  533,  572,  573,  597,  603,\n",
      "         642,  643,  657,  765,  796,  799,  812,  814,  895,  900,  910,  919,\n",
      "        1021, 1025, 1040, 1045, 1083, 1095, 1118, 1308, 1431, 1701, 1811, 2004,\n",
      "        2137, 2343, 2426, 2458, 2785, 2926, 3231, 3472, 5961, 6302])\n",
      "torch.Size([58, 8]) torch.Size([7071, 8])\n",
      "tensor([   8,  262,  457,  706,  918,  971, 1507, 1965, 1982, 2586, 3265, 3461,\n",
      "        3787, 4726, 5000, 5094, 5249, 5373, 5476, 5828, 5966, 6261, 6513, 6535,\n",
      "        6714, 7086, 7221])\n",
      "torch.Size([27, 8]) torch.Size([7129, 8])\n",
      "tensor([  86,  115,  137,  154,  273,  348,  620,  628,  711,  917,  957,  970,\n",
      "        1466, 1645, 1756, 1901, 2110, 2609, 2763, 3283, 3717, 4554, 4826, 5126,\n",
      "        5558, 5862, 7169])\n",
      "torch.Size([27, 8]) torch.Size([7156, 8])\n",
      "tensor([  10,   14,   15,   18,   20,   51,  132,  138,  268,  309,  368,  403,\n",
      "         404,  454,  476,  501,  585,  616,  662,  720,  802,  809,  829,  840,\n",
      "         846,  873,  891,  963,  972,  981,  983,  987, 1003, 1007, 1014, 1018,\n",
      "        1046, 1056, 1070, 1094, 1096, 1098, 1487, 1664, 2105, 2114, 3625, 4273])\n",
      "torch.Size([48, 8]) torch.Size([7183, 8])\n",
      "tensor([  54,   67,   75,   79,   81,  103,  139,  181,  204,  229,  234,  271,\n",
      "         280,  347,  353,  367,  375,  387,  406,  422,  465,  481,  499,  505,\n",
      "         528,  531,  543,  553,  580,  581,  582,  669,  681,  696,  701,  722,\n",
      "         745,  752,  757,  761,  772,  773,  777,  787,  788,  790,  817,  828,\n",
      "         832,  835,  842,  860,  888,  890,  897,  921,  931,  935,  936,  958,\n",
      "         968, 1002, 1011, 1016, 1033, 1044, 1047, 1055, 1066, 1074, 1075, 1082,\n",
      "        1088, 1092, 1093, 4350])\n",
      "torch.Size([76, 8]) torch.Size([7231, 8])\n",
      "tensor([  37,   66,  199,  341,  506,  635,  694,  841, 1037, 1069, 1205, 1307,\n",
      "        1999, 2166, 2697, 3206, 4622, 5011, 5764])\n",
      "torch.Size([19, 8]) torch.Size([7307, 8])\n",
      "tensor([ 358,  389,  593,  664, 6807, 6964, 7303])\n",
      "torch.Size([7, 8]) torch.Size([7326, 8])\n",
      "tensor([   5,  554,  801,  866,  870,  896, 1211, 1382, 1420, 1641, 1678, 1949,\n",
      "        2938, 4004, 4499])\n",
      "torch.Size([15, 8]) torch.Size([7333, 8])\n",
      "tensor([  50,  243,  376,  718,  852,  939,  995, 1038, 2831])\n",
      "torch.Size([9, 8]) torch.Size([7348, 8])\n",
      "tensor(4426)\n",
      "torch.Size([1, 8]) torch.Size([7357, 8])\n",
      "tensor(843)\n",
      "torch.Size([1, 8]) torch.Size([7358, 8])\n",
      "tensor(1065)\n",
      "torch.Size([1, 8]) torch.Size([7359, 8])\n",
      "tensor(9)\n",
      "torch.Size([1, 8]) torch.Size([7360, 8])\n",
      "tensor(1)\n",
      "torch.Size([1, 8]) torch.Size([7361, 8])\n"
     ]
    }
   ],
   "source": [
    "o = write_results(pred, 0.4, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (cv-nd)",
   "language": "python",
   "name": "cv-nd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
